{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"License Plate Recognition System Documentation","text":"<p>This documentation provides a comprehensive overview of the License Plate Recognition System, developed for Zotter Schokoladen GmbH.</p>"},{"location":"#system-architecture","title":"System Architecture","text":"<p>The system is designed as a modular, containerized application stack.  </p>"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li>Set up Environment: Copy the <code>.env.example</code> file to <code>.env</code> and ensure all environment variables are correctly set.</li> <li> <p>Start the System: Use the <code>docker-compose.dev.yaml</code> file or the <code>./run.sh</code> script to start the application stack.</p> <pre><code>./run.sh\n</code></pre> </li> </ol>"},{"location":"#development","title":"Development","text":"<p>For detailed information on setting up a development environment, running tests, and contributing to the project, please see the Development section.</p> <p>Operating System Recommendation</p> <p>This system is developed for a Linux environment. It is strongly recommended to develop on a Unix-based system (Linux or macOS). Windows users may encounter issues with line endings (CRLF vs LF) in scripts and configuration files, which can prevent the system from executing correctly.</p>"},{"location":"#operations","title":"Operations","text":"<p>The Operations section provides guidance on essential maintenance tasks, including:</p> <ul> <li>Backups: Performing manual and automatic database backups.</li> <li>Restore: Restoring the database from a backup.</li> </ul>"},{"location":"#deployment","title":"Deployment","text":"<p>The system is designed for containerized deployment. Refer to the Deployment section for instructions on building and deploying the application in a production environment.</p>"},{"location":"deployment/building-images/","title":"Building and Pushing Docker Images","text":"<p>This section describes how to build the Docker images for the services and push them to a Docker registry.</p>"},{"location":"deployment/building-images/#automated-builds-with-github-actions","title":"Automated Builds with GitHub Actions","text":"<p>The project is configured to automatically build and push Docker images to a Docker registry whenever code is pushed to the <code>main</code> branch. This process is managed by the GitHub Actions workflow defined in <code>.github/workflows/docker-build.yaml</code>.</p> <p>The workflow uses the <code>build.sh</code> script to build and push the images.</p>"},{"location":"deployment/building-images/#secrets","title":"Secrets","text":"<p>The GitHub Actions workflow requires the following secrets to be configured in the repository settings:</p> <ul> <li><code>DOCKER_REGISTRY</code>: The URL of the Docker registry.</li> <li><code>DOCKER_USERNAME</code>: The username for the Docker registry.</li> <li><code>DOCKER_TOKEN</code>: A personal access token with permissions to push images to the registry.</li> </ul>"},{"location":"deployment/building-images/#manual-builds","title":"Manual Builds","text":"<p>You can also build and push the images manually using the <code>build.sh</code> script.</p>"},{"location":"deployment/building-images/#usage","title":"Usage","text":"<pre><code>./build.sh\n</code></pre>"},{"location":"deployment/building-images/#prerequisites","title":"Prerequisites","text":"<p>Before running the script, you need to:</p> <ol> <li>Set the <code>DOCKER_REGISTRY</code> environment variable: This variable must be set in your <code>.env</code> file. It should point to the Docker registry where you want to push the images.</li> <li>Log in to the Docker registry: You need to be authenticated with the Docker registry. You can do this using the <code>docker login</code> command:     <pre><code>docker login &lt;your-docker-registry&gt;\n</code></pre></li> <li>Ensure lock files are present: The script checks for the existence of <code>uv.lock</code> (for Python services) and <code>package-lock.json</code> (for the web service). If these files are missing, you need to generate them by running <code>uv lock</code> or <code>npm install</code> in the respective service directories.</li> </ol>"},{"location":"deployment/building-images/#script-details","title":"Script Details","text":"<p>The <code>build.sh</code> script iterates through all the services in the <code>services</code> directory, builds a Docker image for each service, and then pushes the image to the configured Docker registry. It also builds and pushes images for <code>db-prestart</code>, <code>db-backup</code>, <code>shared-data</code>, and <code>grafana</code>.</p>"},{"location":"deployment/overview/","title":"Architecture Overview","text":"<p>The License Plate Recognition System is a service-oriented application, designed for containerized deployment. The entire system is orchestrated using Docker Compose.</p>"},{"location":"deployment/overview/#services","title":"Services","text":"<p>The system is composed of the following services:</p> <ul> <li><code>analytics-service</code>: Provides analytics and insights on the collected license plate data.</li> <li><code>auth-service</code>: Handles user authentication and authorization, integrating with Active Directory.</li> <li><code>data-collection-service</code>: Polls the Synology NAS for new images, sends them to the Plate Recognizer service, and stores the results in the database.</li> <li><code>notification-service</code>: Sends notifications (e.g., email) based on predefined rules and events.</li> <li><code>web-service</code>: The frontend application, built with Next.js, that provides the user interface for the system.</li> <li><code>plate-recognizer</code>: A third-party service that performs the actual license plate recognition.</li> <li><code>postgres</code>: The PostgreSQL database that stores all the application data.</li> <li><code>db-prestart</code>: A service that runs database migrations before the other services start.</li> <li><code>postgres-backup</code>: A service that performs periodic backups of the database.</li> <li><code>grafana</code>: Visualization Service for the ingestion data from the data-collection service</li> </ul>"},{"location":"deployment/overview/#data-flow","title":"Data Flow","text":"<ol> <li>The <code>data-collection-service</code> periodically fetches images from a Synology NAS.</li> <li>These images are sent to the <code>plate-recognizer</code> service, which detects and reads license plates.</li> <li>The results from the <code>plate-recognizer</code> service are then stored in the <code>postgres</code> database by the <code>data-collection-service</code>.</li> <li>The <code>web-service</code> provides a user interface to view the collected data, and it communicates with the other backend services (<code>analytics-service</code>, <code>notification-service</code>, <code>auth-service</code>) to provide various features.</li> <li>The <code>notification-service</code> can be configured to send alerts based on the data collected.</li> <li>The <code>analytics-service</code> provides data for dashboards and reports in the <code>web-service</code>.</li> </ol>"},{"location":"deployment/overview/#containerization","title":"Containerization","text":"<p>All services are containerized using Docker. This allows for a consistent and reproducible deployment across different environments. The <code>docker-compose.*.yaml</code> files define the services, their dependencies, and their configurations.</p>"},{"location":"deployment/production-setup/","title":"Production Deployment Guide","text":"<p>This guide outlines the steps for deploying the License Plate Recognition System in a production environment.</p>"},{"location":"deployment/production-setup/#1-prerequisites","title":"1. Prerequisites","text":"<ul> <li>A server or cluster with Docker and Docker Compose installed.</li> <li>A Docker registry containing the images for all the services. See the Building and Pushing Docker Images guide for more information.</li> <li>A PostgreSQL database. You can run the database in a Docker container, as shown in the <code>docker-compose.prod.yaml</code> file, or use a managed database service.</li> </ul>"},{"location":"deployment/production-setup/#2-configuration","title":"2. Configuration","text":"<p>Create a <code>.env</code> file on the production server with the appropriate environment variables for your production environment. You can refer to the Configuration guide for a complete list of variables.</p> <p>Important: Do not use the default development passwords...</p>"},{"location":"deployment/production-setup/#3-docker-compose-for-production","title":"3. Docker Compose for Production","text":"<p>The <code>docker-compose.prod.yaml</code> file is provided as a starting point for production deployments. This file is similar to the <code>dev</code> version, but it uses the images from the Docker registry instead of building them locally, and it does not mount the source code volumes.</p> <p>You can use this file directly or adapt it to your needs. If for example you wanted to use k8s.</p>"},{"location":"deployment/production-setup/#4-deployment-steps","title":"4. Deployment Steps","text":"<ol> <li>Copy <code>docker-compose.prod.yaml</code> to the server: Transfer the <code>docker-compose.prod.yaml</code> file to your production server.</li> <li>Create the <code>.env</code> file: Create a <code>.env</code> file on the server with your production configuration.</li> <li>Log in to the Docker registry: If your Docker registry requires authentication (the default one does not), log in using the <code>docker login</code> command.</li> <li> <p>Start the application: Use Docker Compose to start the application in detached mode:</p> <pre><code>docker compose -f docker-compose.prod.yaml up -d\n</code></pre> </li> </ol> <p>This will pull the required images from your Docker registry and start all the services.</p>"},{"location":"development/docker-commands/","title":"Common Docker Commands","text":"<p>This section provides a reference for common Docker commands used in this project.</p>"},{"location":"development/docker-commands/#starting-the-application","title":"Starting the Application","text":"<p>To start the application in development mode with hot-reloading, use the <code>run.sh</code> script:</p> <pre><code>./run.sh\n</code></pre> <p>This is the recommended way to start the application for development.</p> <p>Alternatively, you can use <code>docker compose</code> directly:</p> <pre><code>docker compose -f docker-compose.dev.yaml up --build\n</code></pre> <p>To start the application in production mode, use the <code>docker-compose.prod.yaml</code> file:</p> <pre><code>docker compose -f docker-compose.prod.yaml up -d --build\n</code></pre>"},{"location":"development/docker-commands/#stopping-the-application","title":"Stopping the Application","text":"<p>To stop the application, you can use <code>Ctrl+C</code> in the terminal where the application is running if you did not use the <code>-d</code> flag.</p> <p>If you used the <code>-d</code> flag to run the application in detached mode, you can stop it with:</p> <pre><code>docker compose -f docker-compose.dev.yaml down\n</code></pre> <p>or for production:</p> <pre><code>docker compose -f docker-compose.prod.yaml down\n</code></pre> <p>The <code>run.sh</code> script has a cleanup function that automatically runs <code>docker compose -f docker-compose.dev.yaml down</code> on exit.</p>"},{"location":"development/docker-commands/#viewing-logs","title":"Viewing Logs","text":"<p>To view the logs of all running services, you can use the following command:</p> <pre><code>docker compose -f docker-compose.dev.yaml logs -f\n</code></pre> <p>To view the logs of a specific service, you can specify the service name:</p> <pre><code>docker compose -f docker-compose.dev.yaml logs -f &lt;service-name&gt;\n</code></pre> <p>For example, to view the logs of the <code>data-collection-service</code>:</p> <pre><code>docker compose -f docker-compose.dev.yaml logs -f data-collection-service\n</code></pre>"},{"location":"development/docker-commands/#executing-commands-in-services","title":"Executing Commands in Services","text":"<p>You can execute commands inside a running service container using <code>docker compose exec</code>.</p> <p>For example, to open a shell in the <code>data-collection-service</code> container:</p> <pre><code>docker compose -f docker-compose.dev.yaml exec data-collection-service bash\n</code></pre> <p>This is useful for debugging and running commands within the context of a specific service.</p>"},{"location":"development/docker-commands/#running-one-off-commands","title":"Running One-off Commands","text":"<p>To run a one-off command in a service container, you can use <code>docker compose run</code>. This is particularly useful for tasks like running tests or database migrations.</p> <p>For example, to run <code>pytest</code> in the <code>data-collection-service</code>:</p> <pre><code>docker compose -f docker-compose.dev.yaml run --rm data-collection-service pytest\n</code></pre> <p>The <code>--rm</code> flag automatically removes the container after the command exits.</p>"},{"location":"development/running-commands/","title":"Running Commands","text":"<p>This section explains how to run various development commands, such as running tests and managing database migrations.</p>"},{"location":"development/running-commands/#running-tests-with-pytest","title":"Running Tests with Pytest","text":"<p>Each Python service in this project is equipped with a set of tests that can be run using <code>pytest</code>. To run the tests for a specific service, you can use the <code>docker-compose run</code> command.</p> <p>For example, to run the tests for the <code>data-collection-service</code>:</p> <pre><code>docker compose -f docker-compose.dev.yaml run --rm data-collection-service pytest\n</code></pre> <p>This command starts a new container for the <code>data-collection-service</code>, runs <code>pytest</code>, and then removes the container.</p> <p>You can run tests for other services by replacing <code>data-collection-service</code> with the name of the service you want to test (e.g., <code>notification-service</code>, <code>analytics-service</code>).</p>"},{"location":"development/running-commands/#managing-database-migrations-with-alembic","title":"Managing Database Migrations with Alembic","text":"<p>The project uses Alembic to manage database schema migrations. The migration scripts are located in the <code>db/alembic/versions</code> directory.</p>"},{"location":"development/running-commands/#creating-a-new-migration","title":"Creating a New Migration","text":"<p>When you make changes to the database models (e.g., in <code>services/data-collection-service/src/models/vehicle_observation.py</code>), you need to generate a new migration script.</p> <p>To do this, run the following command:</p> <pre><code>docker compose -f docker-compose.dev.yaml run --rm db-prestart alembic revision --autogenerate -m \"A descriptive message about your changes\"\n</code></pre> <p>This will create a new migration file in the <code>db/alembic/versions</code> directory.</p>"},{"location":"development/running-commands/#applying-migrations","title":"Applying Migrations","text":"<p>The database migrations are automatically applied when the <code>db-prestart</code> service starts. This service runs before any of the other services that depend on the database, ensuring that the schema is up-to-date.</p> <p>If you need to manually apply migrations, you can run:</p> <pre><code>docker compose -f docker-compose.dev.yaml run --rm db-prestart alembic upgrade head\n</code></pre>"},{"location":"development/running-commands/#downgrading-migrations","title":"Downgrading Migrations","text":"<p>To downgrade a migration, you can use the <code>alembic downgrade</code> command. For example, to downgrade by one revision:</p> <pre><code>docker compose -f docker-compose.dev.yaml run --rm db-prestart alembic downgrade -1\n</code></pre>"},{"location":"development/running-commands/#accessing-the-swagger-ui","title":"Accessing the Swagger UI","text":"<p>Each of the Python-based services (e.g., <code>data-collection-service</code>, <code>notification-service</code>) provides the Swagger UI for API testing.</p> <p>To access the Swagger UI for a running service, open your web browser and navigate to:</p> <pre><code>http://localhost:&lt;SERVICE_PORT&gt;/docs\n</code></pre> <p>Replace <code>&lt;SERVICE_PORT&gt;</code> with the port number of the service you want to inspect, as defined in the <code>docker-compose.dev.yaml</code> file.</p>"},{"location":"development/running-commands/#example","title":"Example","text":"<p>For example, to access the Swagger UI for the data-collection-service, which is mapped to port <code>5003</code>:</p> <pre><code>http://localhost:5003/docs\n</code></pre>"},{"location":"development/service-development/","title":"Service Development","text":"<p>This guide outlines the process for developing, adding, and extending Python services in the License Plate Recognition System.</p>"},{"location":"development/service-development/#dependency-management","title":"Dependency Management","text":"<p>Each service uses <code>uv</code> for dependency management. When working on a service, ensure you use <code>uv</code> to manage packages and virtual environments.</p>"},{"location":"development/service-development/#dockerfile","title":"Dockerfile","text":"<p>New services should use the standard <code>uv</code> Dockerfile pattern found in existing services. This ensures consistency and proper caching.</p>"},{"location":"development/service-development/#docker-compose","title":"Docker Compose","text":"<p>When adding a new service, it must be added to BOTH <code>docker-compose.dev.yaml</code> and <code>docker-compose.prod.yaml</code>.</p> <ul> <li>Development (<code>docker-compose.dev.yaml</code>): Use the <code>build</code> context and mount volumes (e.g., <code>./services/&lt;service&gt;/src:/app/src</code>) to enable hot-reloading during development.</li> <li>Production (<code>docker-compose.prod.yaml</code>): Use the built image (e.g., <code>image: julianbierbaum/license-plate-system:&lt;service&gt;</code>) and appropriate restart policies (<code>restart: unless-stopped</code>).</li> </ul>"},{"location":"development/service-development/#environment-variables","title":"Environment Variables","text":"<p>If your service requires environment variables:</p> <ol> <li>Add them to your local <code>.env</code> file.</li> <li>Add them to <code>.env.example</code> so other developers know they are required. But make sure to censor all sensitive variables in this file because its publicly viewable.</li> </ol>"},{"location":"development/service-development/#build-script","title":"Build Script","text":"<p>You should NOT edit the <code>build.sh</code> script if you dont explicitly need to. </p> <p>The <code>build.sh</code> script automatically iterates through directories in <code>services/</code>. It will build and push your service if it detects the following files:</p> <ul> <li><code>Dockerfile</code></li> <li><code>pyproject.toml</code></li> <li><code>uv.lock</code></li> </ul>"},{"location":"development/service-development/#cicd-workflows","title":"CI/CD Workflows","text":"<p>When adding a new service, you MUST update the GitHub Actions workflow at <code>.github/workflows/ci-cd.yaml</code>. Add steps for:</p> <ul> <li>Linting: Run <code>ruff check</code> and <code>ruff format</code> on your service.</li> <li>Testing: Run <code>pytest</code> for your service.</li> </ul> <p>Failure to do this will result in your service not being tested in the CI pipeline.</p>"},{"location":"development/service-development/#documentation","title":"Documentation","text":"<p>When adding or modifying a service, remember to update the relevant documentation:</p> <ul> <li>Configuration: Update <code>docs/getting-started/configuration.md</code> if you added new environment variables.</li> <li>API Reference: Update <code>docs/reference/api.md</code> if your service exposes new API endpoints.</li> </ul>"},{"location":"development/setup/","title":"Development Environment Setup","text":"<p>This guide provides detailed instructions for setting up a local development environment for the License Plate Recognition System.</p>"},{"location":"development/setup/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have installed all the necessary tools as described in the Getting Started Section.</p>"},{"location":"development/troubleshooting/","title":"Troubleshooting","text":"<p>This section lists common issues you might encounter during development and how to resolve them.</p>"},{"location":"development/troubleshooting/#services-are-not-starting","title":"Services are not starting","text":"<p>If the services are not starting correctly, here are a few things to check:</p> <ul> <li><code>.env</code> file: Ensure that your <code>.env</code> file is correctly configured and that all necessary environment variables are set.</li> <li>Docker is running: Make sure that the Docker daemon is running.</li> <li>Ports are available: Check if the ports used by the services are not already in use by other applications. You can see the ports in the <code>docker-compose.dev.yaml</code> file.</li> <li>Docker Compose logs: Check the logs for any error messages:     <pre><code>docker compose -f docker-compose.dev.yaml logs -f\n</code></pre></li> </ul>"},{"location":"development/troubleshooting/#db-prestart-service-fails","title":"<code>db-prestart</code> service fails","text":"<p>If the <code>db-prestart</code> service fails, it is likely due to an issue with the database migrations.</p> <ul> <li>Check the logs: Look at the logs of the <code>db-prestart</code> service for any error messages from Alembic.</li> <li>Migration conflicts: If you have been working on a feature branch and have a conflict with migrations from the <code>main</code> branch, you may need to resolve the conflict manually. You can do this by editing the migration files in <code>db/alembic/versions</code>.</li> </ul>"},{"location":"development/troubleshooting/#permission-errors-with-backup-directory","title":"Permission errors with backup directory","text":"<p>You might need to give write-access to the backup-location folder to all user groups.</p> <p>If you are getting permission errors when running the backup scripts, you can try changing the permissions of the backup directory:</p> <pre><code>sudo chmod -R 777 /path/to/your/backup/directory\n</code></pre>"},{"location":"development/troubleshooting/#buildsh-script-fails","title":"<code>build.sh</code> script fails","text":"<p>If the <code>build.sh</code> script fails, here are a few things to check:</p> <ul> <li><code>DOCKER_REGISTRY</code> environment variable: Make sure that the <code>DOCKER_REGISTRY</code> environment variable is set in your <code>.env</code> file.</li> <li>Lock files: The <code>build.sh</code> script checks for <code>uv.lock</code> and <code>package-lock.json</code> files. If these files are missing, you will need to generate them by running <code>uv lock</code> or <code>npm install</code> in the respective service directories.</li> <li>Docker Hub login: If you are pushing to a private Docker Hub repository, you will need to be logged in to Docker Hub. You can log in with the <code>docker login</code> command.</li> </ul>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>The system is configured using environment variables. These variables are stored in a <code>.env</code> file in the root of the project.</p>"},{"location":"getting-started/configuration/#global","title":"Global","text":"<ul> <li><code>LOG_LEVEL</code>: The log level for all services. Defaults to <code>DEBUG</code> in development and can be set to <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, or <code>CRITICAL</code> in production.</li> <li><code>DOCKER_REGISTRY</code>: The Docker registry to push images to. Used by the <code>build.sh</code> script.</li> </ul>"},{"location":"getting-started/configuration/#database-postgresql","title":"Database (PostgreSQL)","text":"<ul> <li><code>DB_HOST</code>: The hostname of the PostgreSQL database.</li> <li><code>DB_PORT</code>: The port of the PostgreSQL database.</li> <li><code>DB_PORT_EXTERNAL</code>: The external port to map to the PostgreSQL container.</li> <li><code>DB_NAME</code>: The name of the database.</li> <li><code>POSTGRES_ADMIN_USER</code>: The username for the PostgreSQL superuser.</li> <li><code>POSTGRES_ADMIN_PASSWORD</code>: The password for the PostgreSQL superuser.</li> </ul>"},{"location":"getting-started/configuration/#services","title":"Services","text":""},{"location":"getting-started/configuration/#analytics-service","title":"Analytics Service","text":"<ul> <li><code>ANALYTICS_DB_USER</code>: The username for the analytics service to connect to the database.</li> <li><code>ANALYTICS_DB_PASSWORD</code>: The password for the analytics service to connect to the database.</li> <li><code>ANALYTICS_SCHEMA</code>: The database schema for the analytics service.</li> </ul>"},{"location":"getting-started/configuration/#auth-service","title":"Auth Service","text":"<ul> <li><code>ACTIVE_DIRECTORY_URL</code>: The URL of the Active Directory server for authentication.</li> </ul>"},{"location":"getting-started/configuration/#data-collection-service","title":"Data Collection Service","text":"<ul> <li><code>DATA_COLLECTION_DB_USER</code>: The username for the data collection service to connect to the database.</li> <li><code>DATA_COLLECTION_DB_PASSWORD</code>: The password for the data collection service to connect to the database.</li> <li><code>DATA_COLLECTION_SCHEMA</code>: The database schema for the data collection service.</li> <li><code>SYNOLOGY_HOST</code>: The hostname of the Synology NAS.</li> <li><code>SYNOLOGY_USERNAME</code>: The username for the Synology NAS.</li> <li><code>SYNOLOGY_PASSWORD</code>: The password for the Synology NAS.</li> <li><code>PLATE_RECOGNIZER_API_KEY</code>: The API key for the Plate Recognizer service.</li> <li><code>SAVE_IMAGES_FOR_DEBUG</code>: Whether to save images for debugging purposes.</li> <li><code>INTERVAL_SECONDS</code>: The interval in seconds to poll the Synology NAS for new images.</li> <li><code>PLATE_RECOGNIZER_SERVICE_URL</code>: The URL of the Plate Recognizer service.</li> <li><code>SAVE_DIR</code>: The directory to save snapshots to.</li> </ul>"},{"location":"getting-started/configuration/#notification-service","title":"Notification Service","text":"<ul> <li><code>NOTIFICATION_DB_USER</code>: The username for the notification service to connect to the database.</li> <li><code>NOTIFICATION_DB_PASSWORD</code>: The password for the notification service to connect to the database.</li> <li><code>NOTIFICATION_SCHEMA</code>: The database schema for the notification service.</li> <li><code>ANALYTICS_SERVICE_URL</code>: The URL of the analytics service.</li> <li><code>SENDER_ADDRESS</code>: The email address to send notifications from.</li> <li><code>SMTP_RELAY_ADDRESS</code>: The IP address of the SMTP open mail relay.</li> <li><code>SMTP_PORT</code>: The SMTP port (optional, defaults to 25).</li> <li><code>NOTIFICATION_API_KEY</code>: API key for authenticating requests to the notification service.</li> </ul>"},{"location":"getting-started/configuration/#web-service","title":"Web Service","text":"<ul> <li><code>AUTH_SERVICE_URL</code>: The URL of the auth service.</li> <li><code>ANALYTICS_SERVICE_URL</code>: The URL of the analytics service.</li> <li><code>NOTIFICATION_SERVICE_URL</code>: The URL of the notification service.</li> </ul>"},{"location":"getting-started/configuration/#plate-recognizer-service","title":"Plate Recognizer Service","text":"<ul> <li><code>LICENSE_KEY</code>: The license key for the Plate Recognizer service.</li> </ul>"},{"location":"getting-started/configuration/#backup","title":"Backup","text":"<ul> <li><code>BACKUP_DIR</code>: The directory to save backups to.</li> <li><code>BACKUP_RETENTION_DAYS</code>: The number of days to retain automatic backups.</li> <li><code>BACKUP_SCHEDULE</code>: The cron schedule for automatic backups.</li> </ul>"},{"location":"getting-started/configuration/#grafana","title":"Grafana","text":"<ul> <li><code>GRAFANA_ADMIN_USER</code>: The username for Grafana administrative access.</li> <li><code>GRAFANA_ADMIN_PASSWORD</code>: The password for Grafana administrative access.</li> <li><code>GRAFANA_PORT_EXTERNAL</code>: The external port for Grafana access.</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Follow these steps to get the License Plate Recognition System up and running on your local machine for development and testing purposes.</p>"},{"location":"getting-started/installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>First, clone the project repository from GitHub to your local machine:</p> <pre><code>git clone https://github.com/julianbierbaum/license-plate-system.git\ncd license-plate-system\n</code></pre>"},{"location":"getting-started/installation/#2-configure-environment-variables","title":"2. Configure Environment Variables","text":"<p>The system uses a <code>.env</code> file to manage environment variables. A <code>.env.example</code> file is provided with all the required variables. Copy this file to <code>.env</code> and fill in the values for your environment.</p> <pre><code>cp .env.example .env\n</code></pre> <p>Now, open the <code>.env</code> file and populate it with the necessary configuration as described in the Configuration section.</p>"},{"location":"getting-started/installation/#3-start-the-application","title":"3. Start the Application","text":"<p>Once the environment variables are configured, you can start the application stack using Docker Compose. For development, you can use the <code>docker-compose.dev.yaml</code> file.</p> <p>The easiest way to start the system is to use the provided <code>run.sh</code> script:</p> <pre><code>./run.sh\n</code></pre> <p>This script will build the necessary Docker images and start all the services defined in the <code>docker-compose.dev.yaml</code> file.</p> <p>Alternatively, you can use <code>docker-compose</code> directly:</p> <pre><code>docker compose -f docker-compose.dev.yaml up --build\n</code></pre>"},{"location":"getting-started/installation/#4-accessing-the-services","title":"4. Accessing the Services","text":"<p>Once the application is running, you can access the different services at their respective ports, as defined in the <code>docker-compose.dev.yaml</code> file.</p>"},{"location":"getting-started/prerequisites/","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following tools installed on your system:</p> <ul> <li>Docker: The application is fully containerized, so Docker is essential for running the services. You can download and install Docker from the official website.</li> <li>Docker Compose: Docker Compose is used to manage the multi-container application stack.</li> <li>Git: The project is managed with Git. You will need Git to clone the repository and manage versions.</li> <li>Shell Environment: A shell environment like Bash is required to run the provided scripts (<code>.sh</code> files).</li> </ul>"},{"location":"getting-started/prerequisites/#hardware-requirements","title":"Hardware Requirements","text":"<p>In addition to the software prerequisites, the following hardware is required for the system to function correctly:</p> <ul> <li>Synology NAS: A Synology Network Attached Storage (NAS) device is required to store the images from the cameras. The <code>data-collection-service</code> is specifically designed to poll a Synology NAS.</li> <li>IP Cameras: IP cameras are needed to capture the images of the license plates. These cameras should be configured to save the images to the Synology NAS.</li> <li>Server: A server to host the application stack. The server should have enough resources (CPU, RAM, disk space) to run all the Docker containers (or just use the NAS).</li> </ul>"},{"location":"operations/backups/","title":"Backups","text":"<p>This section describes the backup procedures for the License Plate Recognition System.</p>"},{"location":"operations/backups/#automatic-backups","title":"Automatic Backups","text":"<p>The <code>postgres-backup</code> service creates periodic backups of the PostgreSQL database. The schedule for these backups is defined by the <code>BACKUP_SCHEDULE</code> environment variable, which should be in cron format.</p> <p>The retention period for automatic backups is controlled by the <code>BACKUP_RETENTION_DAYS</code> environment variable. Backups older than this number of days will be automatically deleted.</p> <p>If the <code>BACKUP_SCHEDULE</code> variable is not set, no periodic backups will be performed.</p> <p>The backups are stored in the directory specified by the <code>BACKUP_DIR</code> environment variable.</p>"},{"location":"operations/backups/#manual-backups","title":"Manual Backups","text":"<p>You can perform a manual backup at any time using the <code>manual_backup.sh</code> script.</p>"},{"location":"operations/backups/#usage","title":"Usage","text":"<pre><code>./manual_backup.sh &lt;DB_HOST&gt; [DB_PORT]\n</code></pre> <ul> <li><code>&lt;DB_HOST&gt;</code>: The hostname of the database to back up.</li> <li><code>[DB_PORT]</code>: The port of the database. Defaults to <code>5432</code>.</li> </ul>"},{"location":"operations/backups/#example","title":"Example","text":"<p>To back up a local database running on the default port:</p> <pre><code>./manual_backup.sh localhost\n</code></pre> <p>The script will create a compressed backup file in the directory specified by the <code>BACKUP_DIR</code> environment variable. The filename will be in the format <code>&lt;DB_NAME&gt;_manual_&lt;TIMESTAMP&gt;.dump.gz</code>.</p>"},{"location":"operations/backups/#env-file","title":".env File","text":"<p>The <code>manual_backup.sh</code> script requires the following environment variables to be set in the <code>.env</code> file in the project root:</p> <ul> <li><code>DB_NAME</code></li> <li><code>POSTGRES_ADMIN_USER</code></li> <li><code>POSTGRES_ADMIN_PASSWORD</code></li> <li><code>BACKUP_DIR</code></li> </ul>"},{"location":"operations/monitoring/","title":"Monitoring","text":""},{"location":"operations/monitoring/#health-checks","title":"Health Checks","text":"<p>The following services have health checks configured in the <code>docker-compose.yaml</code> files:</p> <ul> <li> <p>PostgreSQL Database (<code>postgres</code>):</p> <ul> <li>A health check is performed to ensure that the PostgreSQL database is ready to accept connections.</li> <li>The command used is <code>pg_isready -U ${POSTGRES_ADMIN_USER} -d ${DB_NAME}</code>.</li> <li>It runs every 5 seconds with a 5-second timeout and 5 retries.</li> </ul> </li> <li> <p>Plate Recognizer (<code>plate-recognizer</code>):</p> <ul> <li>A health check is performed to ensure that the Plate Recognizer service is running.</li> <li>The command used is <code>curl -f http://localhost:8080/</code>.</li> <li>It runs every 5 seconds with a 5-second timeout and 5 retries.</li> </ul> </li> <li> <p>Data Collection Service (<code>data-collection-service</code>):</p> <ul> <li>A health check is performed to ensure that the Data Collection service is running.</li> <li>The command used is <code>curl -f http://localhost:5000/health</code>.</li> <li>It runs every 5 seconds with a 5-second timeout and 5 retries.</li> </ul> </li> <li> <p>Notification Service (<code>notification-service</code>):</p> <ul> <li>A health check is performed to ensure that the Notification service is running.</li> <li>The command used is <code>curl -f http://localhost:5000/health</code>.</li> <li>It runs every 5 seconds with a 5-second timeout and 5 retries.</li> </ul> </li> <li> <p>Database Backup Service (<code>db-backup</code>):</p> <ul> <li>A health check is performed to ensure that the cron daemon is running.</li> <li>The command used is <code>pgrep crond || exit 1</code>.</li> <li>It runs every 5 seconds with a 5-second timeout and 5 retries.</li> </ul> </li> </ul>"},{"location":"operations/monitoring/#logging","title":"Logging","text":"<p>All services are configured to output logs to the console. The log level can be configured via the <code>LOG_LEVEL</code> environment variable in the <code>.env</code> file.</p>"},{"location":"operations/restore/","title":"Restore","text":"<p>This section describes how to restore the database from a backup.</p>"},{"location":"operations/restore/#using-the-restore-script","title":"Using the Restore Script","text":"<p>The <code>restore_backup.sh</code> script is used to restore a database backup. This script will completely erase and replace the current database with the data from the backup file.</p>"},{"location":"operations/restore/#usage","title":"Usage","text":"<pre><code>./restore_backup.sh &lt;PATH_TO_BACKUP_FILE&gt; &lt;DB_HOST&gt; [DB_PORT]\n</code></pre> <ul> <li><code>&lt;PATH_TO_BACKUP_FILE&gt;</code>: The path to the backup file to restore.</li> <li><code>&lt;DB_HOST&gt;</code>: The hostname of the database to restore to.</li> <li><code>[DB_PORT]</code>: The port of the database. Defaults to <code>5432</code>.</li> </ul>"},{"location":"operations/restore/#example","title":"Example","text":"<p>To restore a backup to a local database running on the default port:</p> <pre><code>./restore_backup.sh /path/to/your/backup/file.dump.gz localhost\n</code></pre> <p>The script will prompt you for confirmation before proceeding, as this is a destructive operation.</p>"},{"location":"operations/restore/#env-file","title":".env File","text":"<p>The <code>restore_backup.sh</code> script requires the following environment variables to be set in the <code>.env</code> file in the project root:</p> <ul> <li><code>DB_NAME</code></li> <li><code>POSTGRES_ADMIN_USER</code></li> <li><code>POSTGRES_ADMIN_PASSWORD</code></li> </ul>"},{"location":"operations/restore/#restore-process","title":"Restore Process","text":"<p>The restore script performs the following steps:</p> <ol> <li>Terminates active connections: It disconnects all users from the target database.</li> <li>Drops the database: The existing database is completely deleted.</li> <li>Creates a new database: A new, empty database is created with the same name.</li> <li>Restores the backup: The data from the backup file is imported into the new database.</li> </ol>"},{"location":"reference/api/","title":"API Reference","text":"<p>This document provides a reference for the API endpoints available in the License Plate System.</p>"},{"location":"reference/api/#data-collection-service","title":"Data Collection Service","text":"<p>The Data Collection Service is responsible for receiving vehicle detection data and saving it in the database.</p>"},{"location":"reference/api/#get-health","title":"<code>GET /health</code>","text":"<p>Check the health of the service. This endpoint is used by Docker's health check.</p> <p>Response: Returns a <code>200 OK</code> with a simple JSON body. <pre><code>{\n  \"status\": \"ok\"\n}\n</code></pre></p>"},{"location":"reference/api/#post-apivehicle_detected","title":"<code>POST /api/vehicle_detected</code>","text":"<p>Submit vehicle detection data.</p> Request Body <pre><code>{\n  \"camera\": \"string\"\n}\n</code></pre> <p>Fields</p> Name Type Description <code>camera</code> string The name of the camera that detected the vehicle."},{"location":"reference/api/#notification-service","title":"Notification Service","text":"<p>The Notification Service manages user preferences for notifications and sends email alerts/updates.</p> <p>Authentication Required</p> <p>All notification service endpoints (except <code>/health</code>) require an API key. Include the <code>Authorization</code> header with your API key: <pre><code>Authorization: your-api-key-here\n</code></pre></p>"},{"location":"reference/api/#get-health_1","title":"<code>GET /health</code>","text":"<p>Check the health of the service. This endpoint is used by Docker's health check.</p> <p>Response: Returns a <code>200 OK</code> with a simple JSON body. <pre><code>{\n  \"status\": \"ok\"\n}\n</code></pre></p>"},{"location":"reference/api/#user-preferences","title":"User Preferences","text":""},{"location":"reference/api/#post-apiuser_preferences","title":"<code>POST /api/user_preferences/</code>","text":"<p>Create new user preferences.</p> Request Body <pre><code>{\n  \"name\": \"John Doe\",\n  \"email\": \"john@example.com\",\n  \"receive_alerts\": true,\n  \"receive_updates\": false\n}\n</code></pre> <p>Fields</p> Name Type Description <code>name</code> string The name of the user (5-50 chars). <code>email</code> string The email address of the user. <code>receive_alerts</code> bool Whether the user receives alert emails. <code>receive_updates</code> bool Whether the user receives update emails. <p>Response: Returns the newly created user preferences record.</p>"},{"location":"reference/api/#get-apiuser_preferences","title":"<code>GET /api/user_preferences/</code>","text":"<p>Retrieve all user preferences records.</p> <p>Response: Returns a list of all user preferences records.</p>"},{"location":"reference/api/#get-apiuser_preferencesentry_id","title":"<code>GET /api/user_preferences/{entry_id}</code>","text":"<p>Retrieve user preferences by ID.</p> Parameter Type Description <code>entry_id</code> int The ID of the user preferences to retrieve. <p>Response: Returns the requested user preferences record, or <code>404</code> if not found.</p>"},{"location":"reference/api/#get-apiuser_preferencesby-namename","title":"<code>GET /api/user_preferences/by-name/{name}</code>","text":"<p>Retrieve user preferences by name.</p> Parameter Type Description <code>name</code> string The name of the user to retrieve preferences for. <p>Response: Returns the requested user preferences record, or <code>404</code> if not found.</p>"},{"location":"reference/api/#put-apiuser_preferencesentry_id","title":"<code>PUT /api/user_preferences/{entry_id}</code>","text":"<p>Update user preferences by ID.</p> Parameter Type Description <code>entry_id</code> int The ID of the user preferences to update. Request Body <pre><code>{\n  \"name\": \"Jane Doe\",\n  \"email\": \"jane@example.com\",\n  \"receive_alerts\": false,\n  \"receive_updates\": true\n}\n</code></pre> <p>Fields (all optional)</p> Name Type Description <code>name</code> string The name of the user. <code>email</code> string The email address of the user. <code>receive_alerts</code> bool Whether the user receives alerts. <code>receive_updates</code> bool Whether the user receives updates. <p>Response: Returns the updated user preferences record, or <code>404</code> if not found.</p>"},{"location":"reference/api/#delete-apiuser_preferencesentry_id","title":"<code>DELETE /api/user_preferences/{entry_id}</code>","text":"<p>Delete user preferences by ID.</p> Parameter Type Description <code>entry_id</code> int The ID of the user preferences to delete. <p>Response: Returns <code>204 No Content</code> on success, or <code>404</code> if not found.</p>"},{"location":"reference/api/#notifications","title":"Notifications","text":""},{"location":"reference/api/#post-apinotificationssend","title":"<code>POST /api/notifications/send</code>","text":"<p>Send a notification to users based on their preferences.</p> Request Body <pre><code>{\n  \"notification_type\": \"alert\",\n  \"subject\": \"Security Alert\",\n  \"body\": \"Unauthorized vehicle detected\",\n  \"recipients\": [\"security_team@example.com\"],\n  \"html\": false\n}\n</code></pre> <p>Fields</p> Name Type Required Description <code>notification_type</code> string Yes Either <code>\"alert\"</code> or <code>\"update\"</code>. Determines which users receive the notification. <code>subject</code> string Yes Email subject (max 200 chars). <code>body</code> string Yes Email body content. <code>recipients</code> list No Optional list of specific email addresses to send to. If omitted, sends to all users with matching preference. <code>html</code> bool No If <code>true</code>, send body as HTML. Defaults to <code>false</code>. Response <pre><code>{\n  \"total_recipients\": 2,\n  \"successful\": 2,\n  \"failed\": 0,\n  \"results\": [\n    {\"email\": \"user1@example.com\", \"success\": true},\n    {\"email\": \"user2@example.com\", \"success\": true}\n  ]\n}\n</code></pre>"},{"location":"reference/data-collection-flow/","title":"Data Collection Flow","text":"<p>This diagram illustrates the data collection process in the system.</p> <pre><code>sequenceDiagram\n    autonumber\n    participant C as Camera (Synology)\n    participant DCS as Data Collection Service\n    participant DB as PostgreSQL\n    participant SS as Synology Surveillance Station\n    participant PR as Plate Recognizer (ALPR)\n\n    Note over C, DCS: Event-Triggered (Webhook)\n\n    C-&gt;&gt;DCS: POST /api/vehicle_detected (camera_name)\n    activate DCS\n    DCS-&gt;&gt;DCS: Authenticate Webhook Request\n    DCS-&gt;&gt;DCS: Create Background Task\n    DCS--&gt;&gt;C: 202 Accepted\n    deactivate DCS\n\n    Note over DCS: Background Task Processing\n\n    activate DCS\n    DCS-&gt;&gt;SS: Authenticate (Login)\n    SS--&gt;&gt;DCS: Session ID (SID)\n\n    DCS-&gt;&gt;SS: Get Camera List\n    SS--&gt;&gt;DCS: Camera Data (incl. IDs)\n\n    DCS-&gt;&gt;DCS: Find Camera ID by Name\n\n    DCS-&gt;&gt;SS: Get Snapshot (SID, CameraID)\n    SS--&gt;&gt;DCS: Image Binary (JPG)\n\n    opt Debug Mode Enabled\n        DCS-&gt;&gt;DCS: Save Image to Disk\n    end\n\n    DCS-&gt;&gt;PR: POST /v1/plate-reader/ (Image)\n    PR--&gt;&gt;DCS: JSON Result (Plate, Vehicle Type, etc.)\n\n    loop For each detection in result\n        DCS-&gt;&gt;DCS: Enrich Data (Municipality via logic)\n        DCS-&gt;&gt;DCS: Hash License Plate (Privacy)\n\n        DCS-&gt;&gt;DB: Check for Duplicates (Time window)\n        alt No Duplicate Found\n            DCS-&gt;&gt;DB: INSERT Observation\n            DB--&gt;&gt;DCS: Success\n        else Duplicate Found\n            DCS-&gt;&gt;DCS: Skip Observation\n        end\n    end\n    deactivate DCS</code></pre>"},{"location":"reference/docker-compose/","title":"Docker Compose Reference","text":"<p>This project uses Docker Compose to manage the multi-container application stack. There are two main Docker Compose files: <code>docker-compose.dev.yaml</code> for development and <code>docker-compose.prod.yaml</code> for production.</p>"},{"location":"reference/docker-compose/#docker-composedevyaml","title":"<code>docker-compose.dev.yaml</code>","text":"<p>This file is used for local development.</p> <ul> <li>Builds services locally: It builds the Docker images for the services from the local source code.</li> <li>Hot-reloading: It mounts the source code directories as volumes, which enables hot-reloading when you make changes to the code.</li> <li>Debug-friendly: It sets the <code>LOG_LEVEL</code> to <code>DEBUG</code> by default, providing more verbose logging for development.</li> <li>Health checks: Most services have health checks to ensure they are running correctly.</li> <li>Web-service: The <code>web-service</code> is configured with <code>target: deps</code> and <code>command: npm run dev</code> for a better development experience.</li> </ul>"},{"location":"reference/docker-compose/#docker-composeprodyaml","title":"<code>docker-compose.prod.yaml</code>","text":"<p>This file is intended for production deployments.</p> <ul> <li>Uses pre-built images: It pulls the service images from a Docker registry, rather than building them locally.</li> <li>No volume mounts for source code: The source code is not mounted as volumes, as the images are expected to be self-contained.</li> <li>Restart policy: It includes a <code>restart: unless-stopped</code> policy for the services, so that they are automatically restarted if they crash.</li> <li>Optimized for production: It is configured for production use, with less verbose logging and no development-specific features.</li> </ul>"},{"location":"reference/docker-compose/#key-differences","title":"Key Differences","text":"Feature <code>docker-compose.dev.yaml</code> <code>docker-compose.prod.yaml</code> Image Source Builds from local source Pulls from Docker registry Source Code Mounted as volumes Not mounted Hot-reloading Enabled Disabled <code>LOG_LEVEL</code> <code>DEBUG</code> (default) Set via <code>.env</code> file Restart Policy Not set <code>unless-stopped</code>"},{"location":"reference/scripts/","title":"Scripts Reference","text":"<p>This section provides a reference for the scripts included in this project.</p>"},{"location":"reference/scripts/#runsh","title":"<code>run.sh</code>","text":"<p>This script is used to start the application in development mode.</p> <ul> <li>Usage: <code>./run.sh</code></li> <li>Functionality:<ul> <li>Starts the Docker containers defined in <code>docker-compose.dev.yaml</code>.</li> <li>Enables hot-reloading for the services, so that changes to the source code are automatically applied.</li> <li>Sets up a trap to automatically stop and remove the containers when the script is terminated.</li> </ul> </li> </ul>"},{"location":"reference/scripts/#buildsh","title":"<code>build.sh</code>","text":"<p>This script is used to build and push the Docker images for all the services to a Docker registry.</p> <ul> <li>Usage: <code>./build.sh</code></li> <li>Functionality:<ul> <li>Reads the <code>DOCKER_REGISTRY</code> environment variable from the <code>.env</code> file.</li> <li>Builds a Docker image for each service in the <code>services</code> directory, as well as for <code>db-prestart</code>, <code>db-backup</code>, and <code>shared-data</code>.</li> <li>Pushes the images to the configured Docker registry.</li> </ul> </li> <li>Prerequisites:<ul> <li>The <code>DOCKER_REGISTRY</code> environment variable must be set.</li> <li>You must be logged in to the Docker registry (<code>docker login</code>).</li> <li>Lock files (<code>uv.lock</code>, <code>package-lock.json</code>) must be present.</li> </ul> </li> </ul>"},{"location":"reference/scripts/#manual_backupsh","title":"<code>manual_backup.sh</code>","text":"<p>This script is used to create a manual backup of the PostgreSQL database.</p> <ul> <li>Usage: <code>./manual_backup.sh &lt;DB_HOST&gt; [DB_PORT]</code></li> <li>Functionality:<ul> <li>Connects to the specified database and and creates a compressed backup file.</li> <li>The backup file is stored in the directory specified by the <code>BACKUP_DIR</code> environment variable.</li> </ul> </li> <li>Prerequisites:<ul> <li>The <code>.env</code> file must contain the <code>DB_NAME</code>, <code>POSTGRES_ADMIN_USER</code>, <code>POSTGRES_ADMIN_PASSWORD</code>, and <code>BACKUP_DIR</code> variables.</li> </ul> </li> </ul>"},{"location":"reference/scripts/#restore_backupsh","title":"<code>restore_backup.sh</code>","text":"<p>This script is used to restore the PostgreSQL database from a backup file.</p> <ul> <li>Usage: <code>./restore_backup.sh &lt;PATH_TO_BACKUP_FILE&gt; &lt;DB_HOST&gt; [DB_PORT]</code></li> <li>Functionality:<ul> <li>Drops the existing database.</li> <li>Creates a new database.</li> <li>Restores the data from the specified backup file.</li> </ul> </li> <li>Prerequisites:<ul> <li>The <code>.env</code> file must contain the <code>DB_NAME</code>, <code>POSTGRES_ADMIN_USER</code>, and <code>POSTGRES_ADMIN_PASSWORD</code> variables.</li> </ul> </li> <li>Warning: This is a destructive operation that will completely erase the existing database.</li> </ul>"}]}