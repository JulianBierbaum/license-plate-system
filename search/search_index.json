{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the License Plate Recognition System","text":"<p>This documentation provides a comprehensive overview of the License Plate Recognition System, developed for Zotter Schokoladen GmbH.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li>Set up Environment: Ensure all environment variables are correctly set in your <code>.env</code> file.</li> <li> <p>Start the System: Use the <code>docker-compose.dev.yaml</code> file or the <code>./run.sh</code> script to start the application stack.</p> <pre><code>./run.sh\n</code></pre> </li> </ol>"},{"location":"#development","title":"Development","text":"<p>For detailed information on setting up a development environment, running tests, and contributing to the project, please see the Development section.</p>"},{"location":"#deployment","title":"Deployment","text":"<p>The system is designed for containerized deployment. Refer to the Deployment section for instructions on building and deploying the application in a production environment.</p>"},{"location":"#operations","title":"Operations","text":"<p>The Operations section provides guidance on essential maintenance tasks, including:</p> <ul> <li>Backups: Performing manual and automatic database backups.</li> <li>Restore: Restoring the database from a backup.</li> </ul>"},{"location":"deployment/building-images/","title":"Building and Pushing Docker Images","text":"<p>This section describes how to build the Docker images for the services and push them to a Docker registry.</p>"},{"location":"deployment/building-images/#automated-builds-with-github-actions","title":"Automated Builds with GitHub Actions","text":"<p>The project is configured to automatically build and push Docker images to a Docker registry whenever code is pushed to the <code>main</code> branch. This process is managed by the GitHub Actions workflow defined in <code>.github/workflows/docker-build.yaml</code>.</p> <p>The workflow uses the <code>build.sh</code> script to build and push the images.</p>"},{"location":"deployment/building-images/#secrets","title":"Secrets","text":"<p>The GitHub Actions workflow requires the following secrets to be configured in the repository settings:</p> <ul> <li><code>DOCKER_REGISTRY</code>: The URL of the Docker registry.</li> <li><code>DOCKER_USERNAME</code>: The username for the Docker registry.</li> <li><code>DOCKER_TOKEN</code>: A personal access token with permissions to push images to the registry.</li> </ul>"},{"location":"deployment/building-images/#manual-builds","title":"Manual Builds","text":"<p>You can also build and push the images manually using the <code>build.sh</code> script.</p>"},{"location":"deployment/building-images/#usage","title":"Usage","text":"<pre><code>./build.sh\n</code></pre>"},{"location":"deployment/building-images/#prerequisites","title":"Prerequisites","text":"<p>Before running the script, you need to:</p> <ol> <li>Set the <code>DOCKER_REGISTRY</code> environment variable: This variable must be set in your <code>.env</code> file. It should point to the Docker registry where you want to push the images.</li> <li>Log in to the Docker registry: You need to be authenticated with the Docker registry. You can do this using the <code>docker login</code> command:     <pre><code>docker login &lt;your-docker-registry&gt;\n</code></pre></li> <li>Ensure lock files are present: The script checks for the existence of <code>uv.lock</code> (for Python services) and <code>package-lock.json</code> (for the web service). If these files are missing, you need to generate them by running <code>uv lock</code> or <code>npm install</code> in the respective service directories.</li> </ol>"},{"location":"deployment/building-images/#script-details","title":"Script Details","text":"<p>The <code>build.sh</code> script iterates through all the services in the <code>services</code> directory, builds a Docker image for each service, and then pushes the image to the configured Docker registry. It also builds and pushes images for <code>db-prestart</code>, <code>db-backup</code>, and <code>shared-data</code>.</p>"},{"location":"deployment/environment-vars/","title":"Production Environment Variables","text":"<p>This section provides information about the environment variables required for a production deployment.</p>"},{"location":"deployment/environment-vars/#comprehensive-list-of-variables","title":"Comprehensive List of Variables","text":"<p>A comprehensive list of all environment variables used in the project can be found in the Configuration guide. The same variables are used in both development and production, but their values will differ.</p>"},{"location":"deployment/environment-vars/#production-specific-considerations","title":"Production-Specific Considerations","text":"<p>When configuring the environment variables for a production deployment, please pay special attention to the following:</p> <ul> <li><code>LOG_LEVEL</code>: Set this to <code>INFO</code> or <code>WARNING</code> for production to avoid excessive logging.</li> <li>Database Credentials: Use strong, unique passwords for <code>POSTGRES_ADMIN_PASSWORD</code> and all the service-specific database passwords (<code>ANALYTICS_DB_PASSWORD</code>, <code>DATA_COLLECTION_DB_PASSWORD</code>, <code>NOTIFICATION_DB_PASSWORD</code>).</li> <li><code>ACTIVE_DIRECTORY_URL</code>: Ensure this points to your production Active Directory server.</li> <li><code>SYNOLOGY_HOST</code>: This should be the hostname or IP address of your production Synology NAS.</li> <li><code>PLATE_RECOGNIZER_API_KEY</code> and <code>LICENSE_KEY</code>: Use your production license keys for the Plate Recognizer service.</li> <li>Service URLs: The service URLs (<code>ANALYTICS_SERVICE_URL</code>, <code>NOTIFICATION_SERVICE_URL</code>, <code>AUTH_SERVICE_URL</code>) should point to the correct locations in your production environment. If you are using the provided <code>docker-compose.prod.yaml</code> file, the default values should be correct.</li> <li><code>SENDER_ADDRESS</code>: This should be a valid email address that you want to use for sending notifications in production.</li> <li><code>BACKUP_SCHEDULE</code>: Configure a suitable cron schedule for your production database backups.</li> <li><code>BACKUP_RETENTION_DAYS</code>: Set a reasonable retention period for your backups.</li> </ul>"},{"location":"deployment/environment-vars/#security","title":"Security","text":"<p>It is crucial to manage your production environment variables securely. Do not commit your production <code>.env</code> file to version control. Use a secure method for managing secrets, such as:</p> <ul> <li>A secrets management tool (e.g., HashiCorp Vault, AWS Secrets Manager).</li> <li>Encrypted environment files.</li> <li>The secrets management features of your container orchestrator (e.g., Docker secrets, Kubernetes secrets).</li> </ul>"},{"location":"deployment/overview/","title":"Architecture Overview","text":"<p>The License Plate Recognition System is a microservices-based application, designed for containerized deployment. The entire system is orchestrated using Docker Compose.</p>"},{"location":"deployment/overview/#services","title":"Services","text":"<p>The system is composed of the following services:</p> <ul> <li><code>analytics-service</code>: Provides analytics and insights on the collected license plate data.</li> <li><code>auth-service</code>: Handles user authentication and authorization, integrating with Active Directory.</li> <li><code>data-collection-service</code>: Polls the Synology NAS for new images, sends them to the Plate Recognizer service, and stores the results in the database.</li> <li><code>notification-service</code>: Sends notifications (e.g., email) based on predefined rules and events.</li> <li><code>web-service</code>: The frontend application, built with Next.js, that provides the user interface for the system.</li> <li><code>plate-recognizer</code>: A third-party service that performs the actual license plate recognition.</li> <li><code>postgres</code>: The PostgreSQL database that stores all the application data.</li> <li><code>db-prestart</code>: A service that runs database migrations before the other services start.</li> <li><code>postgres-backup</code>: A service that performs periodic backups of the database.</li> </ul>"},{"location":"deployment/overview/#data-flow","title":"Data Flow","text":"<ol> <li>The <code>data-collection-service</code> periodically fetches images from a Synology NAS.</li> <li>These images are sent to the <code>plate-recognizer</code> service, which detects and reads license plates.</li> <li>The results from the <code>plate-recognizer</code> service are then stored in the <code>postgres</code> database by the <code>data-collection-service</code>.</li> <li>The <code>web-service</code> provides a user interface to view the collected data, and it communicates with the other backend services (<code>analytics-service</code>, <code>notification-service</code>, <code>auth-service</code>) to provide various features.</li> <li>The <code>notification-service</code> can be configured to send alerts based on the data collected.</li> <li>The <code>analytics-service</code> provides data for dashboards and reports in the <code>web-service</code>.</li> </ol>"},{"location":"deployment/overview/#containerization","title":"Containerization","text":"<p>All services are containerized using Docker. This allows for a consistent and reproducible deployment across different environments. The <code>docker-compose.yaml</code> files define the services, their dependencies, and their configurations.</p>"},{"location":"deployment/production-setup/","title":"Production Deployment Guide","text":"<p>This guide outlines the steps for deploying the License Plate Recognition System in a production environment.</p>"},{"location":"deployment/production-setup/#1-prerequisites","title":"1. Prerequisites","text":"<ul> <li>A server or cluster with Docker and Docker Compose installed.</li> <li>A Docker registry containing the images for all the services. See the Building and Pushing Docker Images guide for more information.</li> <li>A PostgreSQL database. You can run the database in a Docker container, as shown in the <code>docker-compose.prod.yaml</code> file, or use a managed database service.</li> </ul>"},{"location":"deployment/production-setup/#2-configuration","title":"2. Configuration","text":"<p>Create a <code>.env</code> file on the production server with the appropriate environment variables for your production environment. You can refer to the Configuration guide for a complete list of variables.</p> <p>Important: Ensure that you use strong, unique passwords for all database users and other secrets. Do not use the default development passwords.</p>"},{"location":"deployment/production-setup/#3-docker-compose-for-production","title":"3. Docker Compose for Production","text":"<p>The <code>docker-compose.prod.yaml</code> file is provided as a starting point for production deployments. This file is similar to the <code>dev</code> version, but it uses the images from the Docker registry instead of building them locally, and it does not mount the source code volumes.</p> <p>You can use this file directly or adapt it to your needs. For example, you might want to use a different container orchestrator like Kubernetes.</p>"},{"location":"deployment/production-setup/#4-deployment-steps","title":"4. Deployment Steps","text":"<ol> <li>Copy <code>docker-compose.prod.yaml</code> to the server: Transfer the <code>docker-compose.prod.yaml</code> file to your production server.</li> <li>Create the <code>.env</code> file: Create a <code>.env</code> file on the server with your production configuration.</li> <li>Log in to the Docker registry: If your Docker registry requires authentication, log in using the <code>docker login</code> command.</li> <li> <p>Start the application: Use Docker Compose to start the application in detached mode:</p> <pre><code>docker-compose -f docker-compose.prod.yaml up -d\n</code></pre> </li> </ol> <p>This will pull the required images from your Docker registry and start all the services.</p>"},{"location":"deployment/production-setup/#5-reverse-proxy-and-ssl","title":"5. Reverse Proxy and SSL","text":"<p>For a production deployment, it is highly recommended to use a reverse proxy (e.g., Nginx, Traefik) in front of the web service. This will allow you to:</p> <ul> <li>Use a custom domain name.</li> <li>Enable SSL/TLS to secure the communication between the users and the application.</li> </ul> <p>The reverse proxy would typically listen on ports 80 and 443 and forward the traffic to the <code>web-service</code> container on port 3000.</p>"},{"location":"development/docker-commands/","title":"Common Docker Commands","text":"<p>This section provides a reference for common Docker commands used in this project.</p>"},{"location":"development/docker-commands/#starting-the-application","title":"Starting the Application","text":"<p>To start the application in development mode with hot-reloading, use the <code>run.sh</code> script:</p> <pre><code>./run.sh\n</code></pre> <p>This is the recommended way to start the application for development.</p> <p>Alternatively, you can use <code>docker-compose</code> directly:</p> <pre><code>docker-compose -f docker-compose.dev.yaml up --build\n</code></pre> <p>To start the application in production mode, use the <code>docker-compose.prod.yaml</code> file:</p> <pre><code>docker-compose -f docker-compose.prod.yaml up -d --build\n</code></pre>"},{"location":"development/docker-commands/#stopping-the-application","title":"Stopping the Application","text":"<p>To stop the application, you can use <code>Ctrl+C</code> in the terminal where the application is running if you did not use the <code>-d</code> flag.</p> <p>If you used the <code>-d</code> flag to run the application in detached mode, you can stop it with:</p> <pre><code>docker-compose -f docker-compose.dev.yaml down\n</code></pre> <p>or for production:</p> <pre><code>docker-compose -f docker-compose.prod.yaml down\n</code></pre> <p>The <code>run.sh</code> script has a cleanup function that automatically runs <code>docker compose down</code> on exit.</p>"},{"location":"development/docker-commands/#viewing-logs","title":"Viewing Logs","text":"<p>To view the logs of all running services, you can use the following command:</p> <pre><code>docker-compose -f docker-compose.dev.yaml logs -f\n</code></pre> <p>To view the logs of a specific service, you can specify the service name:</p> <pre><code>docker-compose -f docker-compose.dev.yaml logs -f &lt;service-name&gt;\n</code></pre> <p>For example, to view the logs of the <code>data-collection-service</code>:</p> <pre><code>docker-compose -f docker-compose.dev.yaml logs -f data-collection-service\n</code></pre>"},{"location":"development/docker-commands/#executing-commands-in-services","title":"Executing Commands in Services","text":"<p>You can execute commands inside a running service container using <code>docker-compose exec</code>.</p> <p>For example, to open a shell in the <code>data-collection-service</code> container:</p> <pre><code>docker-compose -f docker-compose.dev.yaml exec data-collection-service bash\n</code></pre> <p>This is useful for debugging and running commands within the context of a specific service.</p>"},{"location":"development/docker-commands/#running-one-off-commands","title":"Running One-off Commands","text":"<p>To run a one-off command in a service container, you can use <code>docker-compose run</code>. This is particularly useful for tasks like running tests or database migrations.</p> <p>For example, to run <code>pytest</code> in the <code>data-collection-service</code>:</p> <pre><code>docker-compose -f docker-compose.dev.yaml run --rm data-collection-service pytest\n</code></pre> <p>The <code>--rm</code> flag automatically removes the container after the command exits.</p>"},{"location":"development/running-commands/","title":"Running Commands","text":"<p>This section explains how to run various development commands, such as running tests and managing database migrations.</p>"},{"location":"development/running-commands/#running-tests-with-pytest","title":"Running Tests with Pytest","text":"<p>Each Python service in this project is equipped with a set of tests that can be run using <code>pytest</code>. To run the tests for a specific service, you can use the <code>docker-compose run</code> command.</p> <p>For example, to run the tests for the <code>data-collection-service</code>:</p> <pre><code>docker-compose -f docker-compose.dev.yaml run --rm data-collection-service pytest\n</code></pre> <p>This command starts a new container for the <code>data-collection-service</code>, runs <code>pytest</code>, and then removes the container.</p> <p>You can run tests for other services by replacing <code>data-collection-service</code> with the name of the service you want to test (e.g., <code>notification-service</code>, <code>analytics-service</code>).</p>"},{"location":"development/running-commands/#managing-database-migrations-with-alembic","title":"Managing Database Migrations with Alembic","text":"<p>The project uses Alembic to manage database schema migrations. The migration scripts are located in the <code>db/alembic/versions</code> directory.</p>"},{"location":"development/running-commands/#creating-a-new-migration","title":"Creating a New Migration","text":"<p>When you make changes to the database models (e.g., in <code>services/data-collection-service/src/models/vehicle_observation.py</code>), you need to generate a new migration script.</p> <p>To do this, run the following command:</p> <pre><code>docker-compose -f docker-compose.dev.yaml run --rm db-prestart alembic revision --autogenerate -m \"A descriptive message about your changes\"\n</code></pre> <p>This will create a new migration file in the <code>db/alembic/versions</code> directory.</p>"},{"location":"development/running-commands/#applying-migrations","title":"Applying Migrations","text":"<p>The database migrations are automatically applied when the <code>db-prestart</code> service starts. This service runs before any of the other services that depend on the database, ensuring that the schema is up-to-date.</p> <p>If you need to manually apply migrations, you can run:</p> <pre><code>docker-compose -f docker-compose.dev.yaml run --rm db-prestart alembic upgrade head\n</code></pre>"},{"location":"development/running-commands/#downgrading-migrations","title":"Downgrading Migrations","text":"<p>To downgrade a migration, you can use the <code>alembic downgrade</code> command. For example, to downgrade by one revision:</p> <pre><code>docker-compose -f docker-compose.dev.yaml run --rm db-prestart alembic downgrade -1\n</code></pre>"},{"location":"development/setup/","title":"Development Environment Setup","text":"<p>This guide provides detailed instructions for setting up a local development environment for the License Plate Recognition System.</p>"},{"location":"development/setup/#1-prerequisites","title":"1. Prerequisites","text":"<p>Ensure you have installed all the necessary tools as described in the Prerequisites section.</p>"},{"location":"development/setup/#2-cloning-the-repository","title":"2. Cloning the Repository","text":"<p>Clone the project repository from GitHub:</p> <pre><code>git clone &lt;repository-url&gt;\ncd license-plate-system\n</code></pre>"},{"location":"development/setup/#3-configuring-the-environment","title":"3. Configuring the Environment","text":"<p>Create a <code>.env</code> file in the project root. This file will hold all your local configuration. You can refer to the Configuration guide for a complete list of environment variables.</p> <p>For a basic local setup, you will need to define the following variables:</p> <pre><code># PostgreSQL\nDB_HOST=postgres\nDB_PORT=5432\nDB_PORT_EXTERNAL=5432\nDB_NAME=license-plate-system\nPOSTGRES_ADMIN_USER=admin\nPOSTGRES_ADMIN_PASSWORD=admin\n\n# Schemas\nDATA_COLLECTION_SCHEMA=data_collection\nANALYTICS_SCHEMA=analytics\nNOTIFICATION_SCHEMA=notification\n\n# Service Users\nANALYTICS_DB_USER=analytics\nANALYTICS_DB_PASSWORD=analytics\nDATA_COLLECTION_DB_USER=data_collection\nDATA_COLLECTION_DB_PASSWORD=data_collection\nNOTIFICATION_DB_USER=notification\nNOTIFICATION_DB_PASSWORD=notification\n\n# Plate Recognizer\nLICENSE_KEY=\nPLATE_RECOGNIZER_API_KEY=\n\n# Synology\nSYNOLOGY_HOST=\nSYNOLOGY_USERNAME=\nSYNOLOGY_PASSWORD=\n\n# Other\nSAVE_DIR=./snapshots\nINTERVAL_SECONDS=60\nPLATE_RECOGNIZER_SERVICE_URL=http://plate-recognizer:8080/v1/plate-reader/\nACTIVE_DIRECTORY_URL=\nANALYTICS_SERVICE_URL=http://analytics-service:5000\nNOTIFICATION_SERVICE_URL=http://notification-service:5000\nAUTH_SERVICE_URL=http://auth-service:5000\nSENDER_ADDRESS=\n</code></pre>"},{"location":"development/setup/#4-running-the-application","title":"4. Running the Application","text":"<p>Use the <code>run.sh</code> script to start the development stack:</p> <pre><code>./run.sh\n</code></pre> <p>This will start all the services with hot-reloading enabled for the source code. Any changes you make to the code in the <code>services</code> directory will automatically trigger a restart of the corresponding service.</p>"},{"location":"development/setup/#5-database-migrations","title":"5. Database Migrations","text":"<p>The project uses Alembic for database migrations. When you make changes to the database models, you will need to create a new migration script.</p> <p>To create a new migration script, run the following command:</p> <pre><code>docker compose run --rm db-prestart alembic revision --autogenerate -m \"Your migration message\"\n</code></pre> <p>This will generate a new migration script in the <code>db/alembic/versions</code> directory. The migrations are automatically applied when the <code>db-prestart</code> service starts.</p>"},{"location":"development/troubleshooting/","title":"Troubleshooting","text":"<p>This section lists common issues you might encounter during development and how to resolve them.</p>"},{"location":"development/troubleshooting/#services-are-not-starting","title":"Services are not starting","text":"<p>If the services are not starting correctly, here are a few things to check:</p> <ul> <li><code>.env</code> file: Ensure that your <code>.env</code> file is correctly configured and that all necessary environment variables are set.</li> <li>Docker is running: Make sure that the Docker daemon is running.</li> <li>Ports are available: Check if the ports used by the services are not already in use by other applications. You can see the ports in the <code>docker-compose.dev.yaml</code> file.</li> <li>Docker Compose logs: Check the logs for any error messages:     <pre><code>docker-compose -f docker-compose.dev.yaml logs -f\n</code></pre></li> </ul>"},{"location":"development/troubleshooting/#db-prestart-service-fails","title":"<code>db-prestart</code> service fails","text":"<p>If the <code>db-prestart</code> service fails, it is likely due to an issue with the database migrations.</p> <ul> <li>Check the logs: Look at the logs of the <code>db-prestart</code> service for any error messages from Alembic.     <pre><code>docker-compose -f docker-compose.dev.yaml logs -f db-prestart\n</code></pre></li> <li>Migration conflicts: If you have been working on a feature branch and have a conflict with migrations from the <code>main</code> branch, you may need to resolve the conflict manually. You can do this by editing the migration files in <code>db/alembic/versions</code>.</li> </ul>"},{"location":"development/troubleshooting/#permission-errors-with-backup-directory","title":"Permission errors with backup directory","text":"<p>The <code>README.md</code> mentions that you might need to give write-access to the backup-location folder to all user groups.</p> <p>If you are getting permission errors when running the backup scripts, you can try changing the permissions of the backup directory:</p> <pre><code>sudo chmod -R 777 /path/to/your/backup/directory\n</code></pre> <p>Note: Be careful with <code>chmod 777</code>. It gives read, write, and execute permissions to everyone. This is fine for a local development environment, but you should use more restrictive permissions in a production environment.</p>"},{"location":"development/troubleshooting/#buildsh-script-fails","title":"<code>build.sh</code> script fails","text":"<p>If the <code>build.sh</code> script fails, here are a few things to check:</p> <ul> <li><code>DOCKER_REGISTRY</code> environment variable: Make sure that the <code>DOCKER_REGISTRY</code> environment variable is set in your <code>.env</code> file.</li> <li>Lock files: The <code>build.sh</code> script checks for <code>uv.lock</code> and <code>package-lock.json</code> files. If these files are missing, you will need to generate them by running <code>uv lock</code> or <code>npm install</code> in the respective service directories.</li> <li>Docker Hub login: If you are pushing to a private Docker Hub repository, you will need to be logged in to Docker Hub. You can log in with the <code>docker login</code> command.</li> </ul>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>The system is configured using environment variables. These variables are stored in a <code>.env</code> file in the root of the project.</p>"},{"location":"getting-started/configuration/#global","title":"Global","text":"<ul> <li><code>LOG_LEVEL</code>: The log level for all services. Defaults to <code>DEBUG</code> in development and can be set to <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, or <code>CRITICAL</code> in production.</li> <li><code>DOCKER_REGISTRY</code>: The Docker registry to push images to. Used by the <code>build.sh</code> script.</li> </ul>"},{"location":"getting-started/configuration/#database-postgresql","title":"Database (PostgreSQL)","text":"<ul> <li><code>DB_HOST</code>: The hostname of the PostgreSQL database.</li> <li><code>DB_PORT</code>: The port of the PostgreSQL database.</li> <li><code>DB_PORT_EXTERNAL</code>: The external port to map to the PostgreSQL container.</li> <li><code>DB_NAME</code>: The name of the database.</li> <li><code>POSTGRES_ADMIN_USER</code>: The username for the PostgreSQL superuser.</li> <li><code>POSTGRES_ADMIN_PASSWORD</code>: The password for the PostgreSQL superuser.</li> </ul>"},{"location":"getting-started/configuration/#services","title":"Services","text":""},{"location":"getting-started/configuration/#analytics-service","title":"Analytics Service","text":"<ul> <li><code>ANALYTICS_DB_USER</code>: The username for the analytics service to connect to the database.</li> <li><code>ANALYTICS_DB_PASSWORD</code>: The password for the analytics service to connect to the database.</li> <li><code>ANALYTICS_SCHEMA</code>: The database schema for the analytics service.</li> </ul>"},{"location":"getting-started/configuration/#auth-service","title":"Auth Service","text":"<ul> <li><code>ACTIVE_DIRECTORY_URL</code>: The URL of the Active Directory server for authentication.</li> </ul>"},{"location":"getting-started/configuration/#data-collection-service","title":"Data Collection Service","text":"<ul> <li><code>DATA_COLLECTION_DB_USER</code>: The username for the data collection service to connect to the database.</li> <li><code>DATA_COLLECTION_DB_PASSWORD</code>: The password for the data collection service to connect to the database.</li> <li><code>DATA_COLLECTION_SCHEMA</code>: The database schema for the data collection service.</li> <li><code>SYNOLOGY_HOST</code>: The hostname of the Synology NAS.</li> <li><code>SYNOLOGY_USERNAME</code>: The username for the Synology NAS.</li> <li><code>SYNOLOGY_PASSWORD</code>: The password for the Synology NAS.</li> <li><code>PLATE_RECOGNIZER_API_KEY</code>: The API key for the Plate Recognizer service.</li> <li><code>SAVE_IMAGES_FOR_DEBUG</code>: Whether to save images for debugging purposes. Defaults to <code>true</code>.</li> <li><code>INTERVAL_SECONDS</code>: The interval in seconds to poll the Synology NAS for new images.</li> <li><code>PLATE_RECOGNIZER_SERVICE_URL</code>: The URL of the Plate Recognizer service.</li> <li><code>SAVE_DIR</code>: The directory to save snapshots to.</li> </ul>"},{"location":"getting-started/configuration/#notification-service","title":"Notification Service","text":"<ul> <li><code>NOTIFICATION_DB_USER</code>: The username for the notification service to connect to the database.</li> <li><code>NOTIFICATION_DB_PASSWORD</code>: The password for the notification service to connect to the database.</li> <li><code>NOTIFICATION_SCHEMA</code>: The database schema for the notification service.</li> <li><code>ANALYTICS_SERVICE_URL</code>: The URL of the analytics service.</li> <li><code>SENDER_ADDRESS</code>: The email address to send notifications from.</li> </ul>"},{"location":"getting-started/configuration/#web-service","title":"Web Service","text":"<ul> <li><code>AUTH_SERVICE_URL</code>: The URL of the auth service.</li> <li><code>ANALYTICS_SERVICE_URL</code>: The URL of the analytics service.</li> <li><code>NOTIFICATION_SERVICE_URL</code>: The URL of the notification service.</li> </ul>"},{"location":"getting-started/configuration/#plate-recognizer","title":"Plate Recognizer","text":"<ul> <li><code>LICENSE_KEY</code>: The license key for the Plate Recognizer service.</li> </ul>"},{"location":"getting-started/configuration/#backup","title":"Backup","text":"<ul> <li><code>BACKUP_DIR</code>: The directory to save backups to.</li> <li><code>BACKUP_RETENTION_DAYS</code>: The number of days to retain automatic backups.</li> <li><code>BACKUP_SCHEDULE</code>: The cron schedule for automatic backups.</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Follow these steps to get the License Plate Recognition System up and running on your local machine for development and testing purposes.</p>"},{"location":"getting-started/installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>First, clone the project repository from GitHub to your local machine:</p> <pre><code>git clone &lt;repository-url&gt;\ncd license-plate-system\n</code></pre>"},{"location":"getting-started/installation/#2-configure-environment-variables","title":"2. Configure Environment Variables","text":"<p>The system uses a <code>.env</code> file to manage environment variables. You will need to create a <code>.env</code> file in the root of the project and populate it with the necessary configuration.</p> <p>A good starting point is to copy the <code>.env.example</code> file if one exists, or to create a new file and add the variables as described in the Configuration section.</p>"},{"location":"getting-started/installation/#3-start-the-application","title":"3. Start the Application","text":"<p>Once the environment variables are configured, you can start the application stack using Docker Compose. For development, you can use the <code>docker-compose.dev.yaml</code> file.</p> <p>The easiest way to start the system is to use the provided <code>run.sh</code> script:</p> <pre><code>./run.sh\n</code></pre> <p>This script will build the necessary Docker images and start all the services defined in the <code>docker-compose.dev.yaml</code> file.</p> <p>Alternatively, you can use <code>docker-compose</code> directly:</p> <pre><code>docker-compose -f docker-compose.dev.yaml up --build\n</code></pre>"},{"location":"getting-started/installation/#4-accessing-the-services","title":"4. Accessing the Services","text":"<p>Once the application is running, you can access the different services at their respective ports, as defined in the <code>docker-compose.dev.yaml</code> file.</p>"},{"location":"getting-started/prerequisites/","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following tools installed on your system:</p> <ul> <li>Docker: The application is fully containerized, so Docker is essential for running the services. You can download and install Docker from the official website.</li> <li>Docker Compose: Docker Compose is used to manage the multi-container application stack. It is included with Docker Desktop for Windows and macOS. For Linux, you may need to install it separately.</li> <li>Git: The project is managed with Git. You will need Git to clone the repository and manage versions.</li> <li>Shell Environment: A shell environment like Bash is required to run the provided scripts (<code>.sh</code> files).</li> <li>Text Editor/IDE: You will need a text editor or Integrated Development Environment (IDE) to edit configuration files.</li> </ul>"},{"location":"getting-started/prerequisites/#hardware-requirements","title":"Hardware Requirements","text":"<p>In addition to the software prerequisites, the following hardware is required for the system to function correctly:</p> <ul> <li>Synology NAS: A Synology Network Attached Storage (NAS) device is required to store the images from the cameras. The <code>data-collection-service</code> is specifically designed to poll a Synology NAS.</li> <li>IP Cameras: IP cameras are needed to capture the images of the license plates. These cameras should be configured to save the images to the Synology NAS.</li> <li>Server: A server to host the application stack. The server should have enough resources (CPU, RAM, disk space) to run all the Docker containers (or just use the NAS).</li> </ul>"},{"location":"operations/backups/","title":"Backups","text":"<p>This section describes the backup procedures for the License Plate Recognition System.</p>"},{"location":"operations/backups/#automatic-backups","title":"Automatic Backups","text":"<p>The <code>postgres-backup</code> service creates periodic backups of the PostgreSQL database. The schedule for these backups is defined by the <code>BACKUP_SCHEDULE</code> environment variable, which should be in cron format.</p> <p>The retention period for automatic backups is controlled by the <code>BACKUP_RETENTION_DAYS</code> environment variable. Backups older than this number of days will be automatically deleted.</p> <p>If the <code>BACKUP_SCHEDULE</code> variable is not set, no periodic backups will be performed.</p> <p>The backups are stored in the directory specified by the <code>BACKUP_DIR</code> environment variable.</p>"},{"location":"operations/backups/#manual-backups","title":"Manual Backups","text":"<p>You can perform a manual backup at any time using the <code>manual_backup.sh</code> script.</p>"},{"location":"operations/backups/#usage","title":"Usage","text":"<pre><code>./manual_backup.sh &lt;DB_HOST&gt; [DB_PORT]\n</code></pre> <ul> <li><code>&lt;DB_HOST&gt;</code>: The hostname of the database to back up.</li> <li><code>[DB_PORT]</code>: The port of the database. Defaults to <code>5432</code>.</li> </ul>"},{"location":"operations/backups/#example","title":"Example","text":"<p>To back up a local database running on the default port:</p> <pre><code>./manual_backup.sh localhost\n</code></pre> <p>The script will create a compressed backup file in the directory specified by the <code>BACKUP_DIR</code> environment variable. The filename will be in the format <code>&lt;DB_NAME&gt;_manual_&lt;TIMESTAMP&gt;.dump.gz</code>.</p>"},{"location":"operations/backups/#env-file","title":".env File","text":"<p>The <code>manual_backup.sh</code> script requires the following environment variables to be set in the <code>.env</code> file in the project root:</p> <ul> <li><code>DB_NAME</code></li> <li><code>POSTGRES_ADMIN_USER</code></li> <li><code>POSTGRES_ADMIN_PASSWORD</code></li> <li><code>BACKUP_DIR</code></li> </ul>"},{"location":"operations/monitoring/","title":"Monitoring","text":"<p>This section will provide information on monitoring the health and performance of the License Plate Recognition System.</p>"},{"location":"operations/monitoring/#logging","title":"Logging","text":"<p>Details on the logging infrastructure, including how to access and interpret logs from the different services.</p>"},{"location":"operations/monitoring/#health-checks","title":"Health Checks","text":"<p>Information on the health check endpoints for each service and how to use them to monitor the status of the system.</p> <p>(This section is currently under development.)</p>"},{"location":"operations/restore/","title":"Restore","text":"<p>This section describes how to restore the database from a backup.</p>"},{"location":"operations/restore/#using-the-restore-script","title":"Using the Restore Script","text":"<p>The <code>restore_backup.sh</code> script is used to restore a database backup. This script will completely erase and replace the current database with the data from the backup file.</p>"},{"location":"operations/restore/#usage","title":"Usage","text":"<pre><code>./restore_backup.sh &lt;PATH_TO_BACKUP_FILE&gt; &lt;DB_HOST&gt; [DB_PORT]\n</code></pre> <ul> <li><code>&lt;PATH_TO_BACKUP_FILE&gt;</code>: The path to the backup file to restore.</li> <li><code>&lt;DB_HOST&gt;</code>: The hostname of the database to restore to.</li> <li><code>[DB_PORT]</code>: The port of the database. Defaults to <code>5432</code>.</li> </ul>"},{"location":"operations/restore/#example","title":"Example","text":"<p>To restore a backup to a local database running on the default port:</p> <pre><code>./restore_backup.sh /path/to/your/backup/file.dump.gz localhost\n</code></pre> <p>The script will prompt you for confirmation before proceeding, as this is a destructive operation.</p>"},{"location":"operations/restore/#env-file","title":".env File","text":"<p>The <code>restore_backup.sh</code> script requires the following environment variables to be set in the <code>.env</code> file in the project root:</p> <ul> <li><code>DB_NAME</code></li> <li><code>POSTGRES_ADMIN_USER</code></li> <li><code>POSTGRES_ADMIN_PASSWORD</code></li> </ul>"},{"location":"operations/restore/#restore-process","title":"Restore Process","text":"<p>The restore script performs the following steps:</p> <ol> <li>Terminates active connections: It disconnects all users from the target database.</li> <li>Drops the database: The existing database is completely deleted.</li> <li>Creates a new database: A new, empty database is created with the same name.</li> <li>Restores the backup: The data from the backup file is imported into the new database.</li> </ol>"},{"location":"reference/api/","title":"API Reference","text":"<p>This section will provide a detailed reference for the APIs exposed by the different services in the License Plate Recognition System.</p> <p>This may include:</p> <ul> <li>Endpoints for the <code>analytics-service</code>.</li> <li>Endpoints for the <code>auth-service</code>.</li> <li>Endpoints for the <code>notification-service</code>.</li> <li>Endpoints for the <code>data-collection-service</code>.</li> </ul> <p>(This section is currently under development.)</p>"},{"location":"reference/docker-compose/","title":"Docker Compose Reference","text":"<p>This project uses Docker Compose to manage the multi-container application stack. There are two main Docker Compose files: <code>docker-compose.dev.yaml</code> for development and <code>docker-compose.prod.yaml</code> for production.</p>"},{"location":"reference/docker-compose/#docker-composedevyaml","title":"<code>docker-compose.dev.yaml</code>","text":"<p>This file is used for local development.</p> <ul> <li>Builds services locally: It builds the Docker images for the services from the local source code.</li> <li>Hot-reloading: It mounts the source code directories as volumes, which enables hot-reloading when you make changes to the code.</li> <li>Debug-friendly: It sets the <code>LOG_LEVEL</code> to <code>DEBUG</code> by default, providing more verbose logging for development.</li> <li>Exposes ports: It exposes the ports of the services to the host machine, so you can access them directly.</li> </ul>"},{"location":"reference/docker-compose/#docker-composeprodyaml","title":"<code>docker-compose.prod.yaml</code>","text":"<p>This file is intended for production deployments.</p> <ul> <li>Uses pre-built images: It pulls the service images from a Docker registry, rather than building them locally.</li> <li>No volume mounts for source code: The source code is not mounted as volumes, as the images are expected to be self-contained.</li> <li>Restart policy: It includes a <code>restart: unless-stopped</code> policy for the services, so that they are automatically restarted if they crash.</li> <li>Optimized for production: It is configured for production use, with less verbose logging and no development-specific features.</li> </ul>"},{"location":"reference/docker-compose/#key-differences","title":"Key Differences","text":"Feature <code>docker-compose.dev.yaml</code> <code>docker-compose.prod.yaml</code> Image Source Builds from local source Pulls from Docker registry Source Code Mounted as volumes Not mounted Hot-reloading Enabled Disabled <code>LOG_LEVEL</code> <code>DEBUG</code> (default) Set via <code>.env</code> file Restart Policy Not set <code>unless-stopped</code>"},{"location":"reference/scripts/","title":"Scripts Reference","text":"<p>This section provides a reference for the scripts included in this project.</p>"},{"location":"reference/scripts/#runsh","title":"<code>run.sh</code>","text":"<p>This script is used to start the application in development mode.</p> <ul> <li>Usage: <code>./run.sh</code></li> <li>Functionality:<ul> <li>Starts the Docker containers defined in <code>docker-compose.dev.yaml</code>.</li> <li>Enables hot-reloading for the services, so that changes to the source code are automatically applied.</li> <li>Sets up a trap to automatically stop and remove the containers when the script is terminated.</li> </ul> </li> </ul>"},{"location":"reference/scripts/#buildsh","title":"<code>build.sh</code>","text":"<p>This script is used to build and push the Docker images for all the services to a Docker registry.</p> <ul> <li>Usage: <code>./build.sh</code></li> <li>Functionality:<ul> <li>Reads the <code>DOCKER_REGISTRY</code> environment variable from the <code>.env</code> file.</li> <li>Builds a Docker image for each service in the <code>services</code> directory, as well as for <code>db-prestart</code>, <code>db-backup</code>, and <code>shared-data</code>.</li> <li>Pushes the images to the configured Docker registry.</li> </ul> </li> <li>Prerequisites:<ul> <li>The <code>DOCKER_REGISTRY</code> environment variable must be set.</li> <li>You must be logged in to the Docker registry (<code>docker login</code>).</li> <li>Lock files (<code>uv.lock</code>, <code>package-lock.json</code>) must be present.</li> </ul> </li> </ul>"},{"location":"reference/scripts/#manual_backupsh","title":"<code>manual_backup.sh</code>","text":"<p>This script is used to create a manual backup of the PostgreSQL database.</p> <ul> <li>Usage: <code>./manual_backup.sh &lt;DB_HOST&gt; [DB_PORT]</code></li> <li>Functionality:<ul> <li>Connects to the specified database and and creates a compressed backup file.</li> <li>The backup file is stored in the directory specified by the <code>BACKUP_DIR</code> environment variable.</li> </ul> </li> <li>Prerequisites:<ul> <li>The <code>.env</code> file must contain the <code>DB_NAME</code>, <code>POSTGRES_ADMIN_USER</code>, <code>POSTGRES_ADMIN_PASSWORD</code>, and <code>BACKUP_DIR</code> variables.</li> </ul> </li> </ul>"},{"location":"reference/scripts/#restore_backupsh","title":"<code>restore_backup.sh</code>","text":"<p>This script is used to restore the PostgreSQL database from a backup file.</p> <ul> <li>Usage: <code>./restore_backup.sh &lt;PATH_TO_BACKUP_FILE&gt; &lt;DB_HOST&gt; [DB_PORT]</code></li> <li>Functionality:<ul> <li>Drops the existing database.</li> <li>Creates a new database.</li> <li>Restores the data from the specified backup file.</li> </ul> </li> <li>Prerequisites:<ul> <li>The <code>.env</code> file must contain the <code>DB_NAME</code>, <code>POSTGRES_ADMIN_USER</code>, and <code>POSTGRES_ADMIN_PASSWORD</code> variables.</li> </ul> </li> <li>Warning: This is a destructive operation that will completely erase the existing database.</li> </ul>"}]}